{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model Evaluation\n",
                "## 1. Load Data & Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import joblib\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.metrics import *\n",
                "\n",
                "# Load Test Data (Final Holdout)\n",
                "X_test = pd.read_csv('../data/processed/model_ready/X_test.csv')\n",
                "y_test = pd.read_csv('../data/processed/model_ready/y_test.csv').values.ravel()\n",
                "\n",
                "# Load Best Model\n",
                "model = joblib.load('../models/best_model.pkl')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Predictions & Metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_pred = model.predict(X_test)\n",
                "y_prob = model.predict_proba(X_test)[:, 1]\n",
                "\n",
                "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
                "print(\"Precision:\", precision_score(y_test, y_pred))\n",
                "print(\"Recall:\", recall_score(y_test, y_pred))\n",
                "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
                "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. ROC Curve"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
                "plt.figure()\n",
                "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc_score(y_test, y_prob))\n",
                "plt.plot([0, 1], [0, 1], 'k--')\n",
                "plt.xlim([0.0, 1.0])\n",
                "plt.ylim([0.0, 1.05])\n",
                "plt.xlabel('False Positive Rate')\n",
                "plt.ylabel('True Positive Rate')\n",
                "plt.title('Receiver Operating Characteristic')\n",
                "plt.legend(loc=\"lower right\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Confusion Matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cm = confusion_matrix(y_test, y_pred)\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
                "plt.title('Confusion Matrix')\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}